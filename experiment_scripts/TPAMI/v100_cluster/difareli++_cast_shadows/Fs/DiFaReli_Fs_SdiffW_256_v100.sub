#!/bin/bash -l


cfg_name='DiFaReli_Fs_SdiffW_256_v100'
#SBATCH --error=./output/${cfg_name}.err.%j # STDOUT output is written in slurm.out.JOBID
#SBATCH --output=./output/${cfg_name}.task.out.%j # STDOUT error is written in slurm.err.JOBID
#SBATCH --job-name=${cfg_name}      # Job name
#SBATCH --mem=128GB                  # Memory request for this job
#SBATCH --nodes=1                   # The number of nodes
#SBATCH --partition=gpu-cluster
#SBATCH --account=vision
#SBATCH --time=3-00:0:0                # Runing time 2 hours
#SBATCH --gpus=4                    # A number of GPUs

path='/ist/users/puntawatp/Dev/DiFaReli/difareli-faster'
model_path='/ist/ist-share/vision/mint/model_logs/'
logger_path='/ist/ist-share/vision/mint/tb_logs/'

conda activate /ist/users/puntawatp/miniconda3/envs/3dr_conda_training

cmd="${path}/train_scripts/image_train.py --train.log_dir ${model_path}/${cfg_name} --train.logger_dir ${logger_path} --train.batch_size 5 --train.n_gpus 4 --cfg ${path}/config/TPAMI/cast_shadows/Finale/v100/${cfg_name}.yaml --train.save_interval 5000 --train.logger_mode tb"

echo $cmd
python $cmd
