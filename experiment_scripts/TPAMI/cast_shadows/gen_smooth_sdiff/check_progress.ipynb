{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os, tqdm, sys\n",
    "import re\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 20)   # figsize\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        \n",
    "def face_segment(segment_part, img):\n",
    "    \n",
    "    if isinstance(img, Image.Image):\n",
    "        face_segment_anno = np.array(img)\n",
    "    else:\n",
    "        face_segment_anno = img\n",
    "        \n",
    "    bg = (face_segment_anno == 0)\n",
    "    skin = (face_segment_anno == 1)\n",
    "    l_brow = (face_segment_anno == 2)\n",
    "    r_brow = (face_segment_anno == 3)\n",
    "    l_eye = (face_segment_anno == 4)\n",
    "    r_eye = (face_segment_anno == 5)\n",
    "    eye_g = (face_segment_anno == 6)\n",
    "    l_ear = (face_segment_anno == 7)\n",
    "    r_ear = (face_segment_anno == 8)\n",
    "    ear_r = (face_segment_anno == 9)\n",
    "    nose = (face_segment_anno == 10)\n",
    "    mouth = (face_segment_anno == 11)\n",
    "    u_lip = (face_segment_anno == 12)\n",
    "    l_lip = (face_segment_anno == 13)\n",
    "    neck = (face_segment_anno == 14)\n",
    "    neck_l = (face_segment_anno == 15)\n",
    "    cloth = (face_segment_anno == 16)\n",
    "    hair = (face_segment_anno == 17)\n",
    "    hat = (face_segment_anno == 18)\n",
    "    face = np.logical_or.reduce((skin, l_brow, r_brow, l_eye, r_eye, eye_g, l_ear, r_ear, ear_r, nose, mouth, u_lip, l_lip))\n",
    "\n",
    "    if segment_part == 'faceseg_face':\n",
    "        seg_m = face\n",
    "    elif segment_part == 'faceseg_head':\n",
    "        seg_m = (face | neck | hair)\n",
    "    elif segment_part == 'faceseg_nohead':\n",
    "        seg_m = ~(face | neck | hair)\n",
    "    elif segment_part == 'faceseg_face&hair':\n",
    "        seg_m = ~bg\n",
    "    elif segment_part == 'faceseg_bg_noface&nohair':\n",
    "        seg_m = (bg | hat | neck | neck_l | cloth) \n",
    "    elif segment_part == 'faceseg_bg&ears_noface&nohair':\n",
    "        seg_m = (bg | hat | neck | neck_l | cloth) | (l_ear | r_ear | ear_r)\n",
    "    elif segment_part == 'faceseg_bg':\n",
    "        seg_m = bg\n",
    "    elif segment_part == 'faceseg_bg&noface':\n",
    "        seg_m = (bg | hair | hat | neck | neck_l | cloth)\n",
    "    elif segment_part == 'faceseg_hair':\n",
    "        seg_m = hair\n",
    "    elif segment_part == 'faceseg_faceskin':\n",
    "        seg_m = skin\n",
    "    elif segment_part == 'faceseg_faceskin&nose':\n",
    "        seg_m = (skin | nose)\n",
    "    elif segment_part == 'faceseg_eyes&glasses&mouth&eyebrows':\n",
    "        seg_m = (l_eye | r_eye | eye_g | l_brow | r_brow | mouth)\n",
    "    elif segment_part == 'faceseg_faceskin&nose&mouth&eyebrows':\n",
    "        seg_m = (skin | nose | mouth | u_lip | l_lip | l_brow | r_brow | l_eye | r_eye)\n",
    "    elif segment_part == 'faceseg_faceskin&nose&mouth&eyebrows&eyes&glasses':\n",
    "        seg_m = (skin | nose | mouth | u_lip | l_lip | l_brow | r_brow | l_eye | r_eye | eye_g)\n",
    "    elif segment_part == 'faceseg_face_noglasses':\n",
    "        seg_m = (~eye_g & face)\n",
    "    elif segment_part == 'faceseg_face_noglasses_noeyes':\n",
    "        seg_m = (~(l_eye | r_eye) & ~eye_g & face)\n",
    "    elif segment_part == 'faceseg_eyes&glasses':\n",
    "        seg_m = (l_eye | r_eye | eye_g)\n",
    "    elif segment_part == 'glasses':\n",
    "        seg_m = eye_g\n",
    "    elif segment_part == 'faceseg_eyes':\n",
    "        seg_m = (l_eye | r_eye)\n",
    "    # elif (segment_part == 'sobel_bg_mask') or (segment_part == 'laplacian_bg_mask') or (segment_part == 'sobel_bin_bg_mask'):\n",
    "    elif segment_part in ['sobel_bg_mask', 'laplacian_bg_mask', 'sobel_bin_bg_mask']:\n",
    "        seg_m = ~(face | neck | hair)\n",
    "    elif segment_part in ['canny_edge_bg_mask']:\n",
    "        seg_m = ~(face | neck | hair) | (l_ear | r_ear)\n",
    "    else: raise NotImplementedError(f\"Segment part: {segment_part} is not found!\")\n",
    "    \n",
    "    out = seg_m\n",
    "    return out\n",
    "\n",
    "def get_shadow_diff(img1, img2, c_type='L', signed=False):\n",
    "    # Compute Shadow Difference\n",
    "    img1 = np.array(img1.convert(c_type)) / 255.0\n",
    "    img2 = np.array(img2.convert(c_type)) / 255.0\n",
    "    if signed:\n",
    "        shadow_diff = img2 - img1\n",
    "    else:\n",
    "        shadow_diff = np.abs(img2 - img1)\n",
    "    return shadow_diff\n",
    "\n",
    "def create_image_grid(images, n_rows=1):\n",
    "    \"\"\"\n",
    "    Creates a grid of images from a list of NumPy arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    - images: List of np.array, each representing an image.\n",
    "    - n_rows: Number of rows in the grid.\n",
    "    \n",
    "    Returns:\n",
    "    - A matplotlib figure containing the image grid.\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "    n_cols = (n_images + n_rows - 1) // n_rows  # Calculate number of columns needed\n",
    "    \n",
    "    # Get the height and width of the images (assuming all images are the same size)\n",
    "    # img_height, img_width = images[0].shape[:2]\n",
    "\n",
    "    # Add zero images if the number of images is less than needed to fill the grid\n",
    "    images += [np.zeros_like(images[0]) for _ in range(n_rows * n_cols - n_images)]\n",
    "    \n",
    "    # Create the grid by concatenating images\n",
    "    rows = []\n",
    "    for i in range(n_rows):\n",
    "        row_images = images[i * n_cols:(i + 1) * n_cols]\n",
    "        rows.append(np.concatenate(row_images, axis=1))\n",
    "    \n",
    "    grid_image = np.concatenate(rows, axis=0)\n",
    "    return grid_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings up the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#] Adding Shadow...\n",
      "Available:  ['shadow']\n",
      "/data/mint/DPM_Dataset/Soften_Strengthen_Shadows/TPAMI/FFHQ_shadow_face/log=difareli_canny=153to204bg_256_vll_cfg=difareli_canny=153to204bg_256_vll.yaml_tomax_steps=50/ema_085000/valid//shadow/reverse_sampling/\n",
      "[#] Done: shadow => 10000/10000 => 100.00%\n",
      "[#] Empty: 0/10000 => 0.00%\n",
      "[#] Empty: []\n",
      "====================================================================================================\n",
      "[#] Adding Diffuse...\n",
      "Available:  ['shadow']\n",
      "/data/mint/DPM_Dataset/Soften_Strengthen_Shadows/TPAMI/FFHQ_diffuse_face/log=Masked_Face_woclip+BgNoHead+shadow_256_cfg=Masked_Face_woclip+BgNoHead+shadow_256.yaml_tomin_steps=50/ema_085000/valid//shadow/reverse_sampling/\n",
      "[#] Done: shadow => 10000/10000 => 100.00%\n",
      "[#] Empty: 0/10000 => 0.00%\n",
      "[#] Empty: []\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "data_path = '/data/mint/DPM_Dataset/ffhq_256_with_anno/'\n",
    "set_ = 'valid'\n",
    "image_path = f'{data_path}/ffhq_256/{set_}/'\n",
    "mask_path = f'{data_path}/face_segment/{set_}/anno/'\n",
    "shadows_path = f'{data_path}/shadow_masks/{set_}/'\n",
    "ckpt = 'ema_085000'\n",
    "\n",
    "\n",
    "def progress(mode, model, n_frames, sampling_path, mothership=False):\n",
    "    total = 10000 if set_ == 'valid' else 60000\n",
    "    if mothership:\n",
    "        progress_path = sampling_path\n",
    "    else:\n",
    "        if set_ == 'train':\n",
    "            progress_path = f'/data/mint/DPM_Dataset/Soften_Strengthen_Shadows/TPAMI/{mode}/{model}/{ckpt}/train_sub/'\n",
    "        else:\n",
    "            progress_path = f'/data/mint/DPM_Dataset/Soften_Strengthen_Shadows/TPAMI/{mode}/{model}/{ckpt}/{set_}/'\n",
    "    if os.path.exists(progress_path):\n",
    "        print(\"Available: \", sorted(os.listdir(progress_path)))\n",
    "    \n",
    "    img_path = []\n",
    "    for p in sorted(os.listdir(progress_path)):\n",
    "        if set_ == 'train':\n",
    "            start = int(p.split('_')[1])\n",
    "            end = int(p.split('_')[3])\n",
    "            n = end - start\n",
    "            tail = f'{progress_path}/{p}/shadow/reverse_sampling/'\n",
    "        elif set_ == 'valid':\n",
    "            assert p == 'shadow'\n",
    "            n = 1\n",
    "            tail = f'{progress_path}/shadow/reverse_sampling/'\n",
    "            start = '60000'\n",
    "        else: raise NotImplementedError(f\"Set: {set_} is not found!\")\n",
    "        print(tail)\n",
    "        done_count = 0\n",
    "        empty_count = 0\n",
    "        empty_name = []\n",
    "        for t in sorted(os.listdir(tail)):\n",
    "            tmp = f'{tail}/{t}/dst={start}.jpg/Lerp_1000/n_frames={n_frames}/'\n",
    "            if not os.path.exists(tmp):\n",
    "                continue\n",
    "            if len(os.listdir(tmp)) == n_frames * 2 + 1:\n",
    "                done_count += 1\n",
    "            else: \n",
    "                empty_count += 1\n",
    "                empty_name.append(t)\n",
    "            img_path.append(tmp)\n",
    "            \n",
    "        print(f'[#] Done: {p} => {done_count}/{total} => {done_count * 100/total:.2f}%')\n",
    "        print(f'[#] Empty: {empty_count}/{total} => {empty_count * 100/total:.2f}%')\n",
    "        print(f'[#] Empty: {empty_name}')\n",
    "    return img_path\n",
    "            \n",
    "        \n",
    "def get_img_path(set_, mode, n_frames, mothership):\n",
    "    # Sampling\n",
    "\n",
    "    if mode == 'FFHQ_diffuse_face':\n",
    "        model = 'log=Masked_Face_woclip+BgNoHead+shadow_256_cfg=Masked_Face_woclip+BgNoHead+shadow_256.yaml_tomin_steps=50'\n",
    "    elif mode == 'FFHQ_shadow_face':\n",
    "        model = 'log=difareli_canny=153to204bg_256_vll_cfg=difareli_canny=153to204bg_256_vll.yaml_tomax_steps=50'\n",
    "\n",
    "    if set_ == 'train':\n",
    "        sampling_path = f'/data/mint/sampling/TPAMI/{mode}/{model}/ema_085000/train_sub'\n",
    "    else:\n",
    "        sampling_path = f'/data/mint/sampling/TPAMI/{mode}/{model}/ema_085000/{set_}'\n",
    "        \n",
    "    img_path= sum([progress(mode=mode, model=model, n_frames=n_frames, sampling_path=sampling_path, mothership=ms) for ms in mothership], [])\n",
    "    # regex src=([0-9]+).jpg/dst=([0-9]+).jpg from path\n",
    "    sj_dict = {}\n",
    "    for p in img_path:\n",
    "        src = re.findall(r'src=([0-9]+).jpg', p)\n",
    "        assert len(src) == 1\n",
    "        dst = re.findall(r'dst=([0-9]+).jpg', p)\n",
    "        assert len(dst) == 1\n",
    "        \n",
    "        sj_dict[src[0]] = p\n",
    "        \n",
    "    return img_path, sj_dict\n",
    "\n",
    "n_frames_shadow = 5\n",
    "n_frames_diffuse = 3\n",
    "print(\"[#] Adding Shadow...\")\n",
    "shadow_img, shadow_dict = get_img_path(set_=set_, mode='FFHQ_shadow_face', n_frames=n_frames_shadow, mothership=[False])\n",
    "print(\"=\" * 100)\n",
    "print(\"[#] Adding Diffuse...\")\n",
    "diffuse, diffuse_dict = get_img_path(set_=set_, mode='FFHQ_diffuse_face', n_frames=n_frames_diffuse, mothership=[False])\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8456\n"
     ]
    }
   ],
   "source": [
    "out_dict = {k: {'shadow':shadow_dict[k], 'diffuse':diffuse_dict[k]} for k in shadow_dict if k in diffuse_dict}\n",
    "# print(out_dict)\n",
    "print(len(out_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpm_sampling_deca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
