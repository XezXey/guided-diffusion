{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os, tqdm, sys\n",
    "import re\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 20)   # figsize\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        \n",
    "def face_segment(segment_part, img):\n",
    "    \n",
    "    if isinstance(img, Image.Image):\n",
    "        face_segment_anno = np.array(img)\n",
    "    else:\n",
    "        face_segment_anno = img\n",
    "        \n",
    "    bg = (face_segment_anno == 0)\n",
    "    skin = (face_segment_anno == 1)\n",
    "    l_brow = (face_segment_anno == 2)\n",
    "    r_brow = (face_segment_anno == 3)\n",
    "    l_eye = (face_segment_anno == 4)\n",
    "    r_eye = (face_segment_anno == 5)\n",
    "    eye_g = (face_segment_anno == 6)\n",
    "    l_ear = (face_segment_anno == 7)\n",
    "    r_ear = (face_segment_anno == 8)\n",
    "    ear_r = (face_segment_anno == 9)\n",
    "    nose = (face_segment_anno == 10)\n",
    "    mouth = (face_segment_anno == 11)\n",
    "    u_lip = (face_segment_anno == 12)\n",
    "    l_lip = (face_segment_anno == 13)\n",
    "    neck = (face_segment_anno == 14)\n",
    "    neck_l = (face_segment_anno == 15)\n",
    "    cloth = (face_segment_anno == 16)\n",
    "    hair = (face_segment_anno == 17)\n",
    "    hat = (face_segment_anno == 18)\n",
    "    face = np.logical_or.reduce((skin, l_brow, r_brow, l_eye, r_eye, eye_g, l_ear, r_ear, ear_r, nose, mouth, u_lip, l_lip))\n",
    "\n",
    "    if segment_part == 'faceseg_face':\n",
    "        seg_m = face\n",
    "    elif segment_part == 'faceseg_head':\n",
    "        seg_m = (face | neck | hair)\n",
    "    elif segment_part == 'faceseg_nohead':\n",
    "        seg_m = ~(face | neck | hair)\n",
    "    elif segment_part == 'faceseg_face&hair':\n",
    "        seg_m = ~bg\n",
    "    elif segment_part == 'faceseg_bg_noface&nohair':\n",
    "        seg_m = (bg | hat | neck | neck_l | cloth) \n",
    "    elif segment_part == 'faceseg_bg&ears_noface&nohair':\n",
    "        seg_m = (bg | hat | neck | neck_l | cloth) | (l_ear | r_ear | ear_r)\n",
    "    elif segment_part == 'faceseg_bg':\n",
    "        seg_m = bg\n",
    "    elif segment_part == 'faceseg_bg&noface':\n",
    "        seg_m = (bg | hair | hat | neck | neck_l | cloth)\n",
    "    elif segment_part == 'faceseg_hair':\n",
    "        seg_m = hair\n",
    "    elif segment_part == 'faceseg_faceskin':\n",
    "        seg_m = skin\n",
    "    elif segment_part == 'faceseg_faceskin&nose':\n",
    "        seg_m = (skin | nose)\n",
    "    elif segment_part == 'faceseg_faceskin&nose&mouth&eyebrows':\n",
    "        seg_m = (skin | nose | mouth | u_lip | l_lip | l_brow | r_brow | l_eye | r_eye)\n",
    "    elif segment_part == 'faceseg_faceskin&nose&mouth&eyebrows&eyes&glasses':\n",
    "        seg_m = (skin | nose | mouth | u_lip | l_lip | l_brow | r_brow | l_eye | r_eye | eye_g)\n",
    "        # seg_m = (skin | nose | mouth | u_lip | l_lip | l_brow | r_brow)\n",
    "    elif segment_part == 'faceseg_face_noglasses':\n",
    "        seg_m = (~eye_g & face)\n",
    "    elif segment_part == 'faceseg_face_noglasses_noeyes':\n",
    "        seg_m = (~(l_eye | r_eye) & ~eye_g & face)\n",
    "    elif segment_part == 'faceseg_eyes&glasses':\n",
    "        seg_m = (l_eye | r_eye | eye_g)\n",
    "    elif segment_part == 'glasses':\n",
    "        seg_m = eye_g\n",
    "    elif segment_part == 'faceseg_eyes':\n",
    "        seg_m = (l_eye | r_eye)\n",
    "    # elif (segment_part == 'sobel_bg_mask') or (segment_part == 'laplacian_bg_mask') or (segment_part == 'sobel_bin_bg_mask'):\n",
    "    elif segment_part in ['sobel_bg_mask', 'laplacian_bg_mask', 'sobel_bin_bg_mask']:\n",
    "        seg_m = ~(face | neck | hair)\n",
    "    elif segment_part in ['canny_edge_bg_mask']:\n",
    "        seg_m = ~(face | neck | hair) | (l_ear | r_ear)\n",
    "    else: raise NotImplementedError(f\"Segment part: {segment_part} is not found!\")\n",
    "    \n",
    "    out = seg_m\n",
    "    return out\n",
    "    \n",
    "\n",
    "def get_shadow_diff(img1, img2, c_type='L', signed=False):\n",
    "    # Compute Shadow Difference\n",
    "    img1 = np.array(img1.convert(c_type)) / 255.0\n",
    "    img2 = np.array(img2.convert(c_type)) / 255.0\n",
    "    if signed:\n",
    "        shadow_diff = img2 - img1\n",
    "    else:\n",
    "        shadow_diff = np.abs(img2 - img1)\n",
    "    return shadow_diff\n",
    "\n",
    "def create_image_grid(images, n_rows=1):\n",
    "    \"\"\"\n",
    "    Creates a grid of images from a list of NumPy arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    - images: List of np.array, each representing an image.\n",
    "    - n_rows: Number of rows in the grid.\n",
    "    \n",
    "    Returns:\n",
    "    - A matplotlib figure containing the image grid.\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "    n_cols = (n_images + n_rows - 1) // n_rows  # Calculate number of columns needed\n",
    "    \n",
    "    # Get the height and width of the images (assuming all images are the same size)\n",
    "    # img_height, img_width = images[0].shape[:2]\n",
    "\n",
    "    # Add zero images if the number of images is less than needed to fill the grid\n",
    "    images += [np.zeros_like(images[0]) for _ in range(n_rows * n_cols - n_images)]\n",
    "    \n",
    "    # Create the grid by concatenating images\n",
    "    rows = []\n",
    "    for i in range(n_rows):\n",
    "        row_images = images[i * n_cols:(i + 1) * n_cols]\n",
    "        rows.append(np.concatenate(row_images, axis=1))\n",
    "    \n",
    "    grid_image = np.concatenate(rows, axis=0)\n",
    "    return grid_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings up the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "data_path = '/data/mint/DPM_Dataset/ffhq_256_with_anno/'\n",
    "set_ = 'train'\n",
    "image_path = f'{data_path}/ffhq_256/{set_}/'\n",
    "mask_path = f'{data_path}/face_segment/{set_}/anno/'\n",
    "shadows_path = f'{data_path}/shadow_masks/{set_}/'\n",
    "\n",
    "# Sampling\n",
    "reshadow_path = ''\n",
    "model = 'log=Masked_Face_woclip+BgNoHead+shadow_256_cfg=Masked_Face_woclip+BgNoHead+shadow_256.yaml_tomin_steps=50'\n",
    "n_frames = 3\n",
    "sampling_path = f'/data/mint/sampling/TPAMI/FFHQ_diffuse_face/{model}/ema_085000/train_sub'\n",
    "ckpt = 'ema_085000'\n",
    "\n",
    "def progress(vid, mothership=False):\n",
    "    if mothership:\n",
    "        progress_path = sampling_path\n",
    "    else:\n",
    "        progress_path = f'/data/mint/sampling/TPAMI/FFHQ_diffuse_face/mount_sampling/v{vid}/{model}/{ckpt}/train_sub/'\n",
    "    print(os.listdir(progress_path))\n",
    "    \n",
    "    img_path = []\n",
    "    for p in sorted(os.listdir(progress_path)):\n",
    "        start = int(p.split('_')[1])\n",
    "        end = int(p.split('_')[3])\n",
    "        n = end - start\n",
    "        tail = f'{progress_path}/{p}/shadow/reverse_sampling/'\n",
    "        count = 0\n",
    "        for t in sorted(os.listdir(tail)):\n",
    "            tmp = f'{tail}/{t}/dst={start}.jpg/Lerp_1000/n_frames={n_frames}/'\n",
    "            assert len(os.listdir(tmp)) == n_frames * 2 + 1\n",
    "            count += 1\n",
    "            img_path.append(tmp)\n",
    "            \n",
    "        print(f'[#] {p} => {count}/{n} => {count * 100/n:.2f}%')\n",
    "    return img_path\n",
    "            \n",
    "        \n",
    "# img_path = progress(vid='11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "img_name = re.findall(r\"src=\\d+\\.jpg\", img_path[idx])[0].split('=')[1].split('.')[0]\n",
    "face_image = Image.open(f'{image_path}/{img_name}.jpg')\n",
    "mask_image = Image.open(f'{mask_path}/anno_{img_name}.png')\n",
    "m_face = face_segment('faceseg_faceskin&nose&mouth&eyebrows', mask_image)\n",
    "m_glasses = face_segment('glasses', mask_image)\n",
    "m_glasses_and_eyes = face_segment('faceseg_eyes&glasses', mask_image)\n",
    "reshadow_img = [face_image] + [Image.open(f'{img_path[idx]}/res_frame{f}.png') for f in range(n_frames)]\n",
    "plt.figure(figsize=(30, 30))\n",
    "plt.imshow(create_image_grid(reshadow_img, 1), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "c_type = 'L'\n",
    "out = []\n",
    "for i in range(len(reshadow_img)):\n",
    "    out.append(get_shadow_diff(img1=reshadow_img[i], img2=reshadow_img[0], c_type=c_type, signed=True))\n",
    "\n",
    "print(\"[#] Shadow difference: \")\n",
    "plt.figure(figsize=(30, 30))\n",
    "plt.imshow(create_image_grid(out, 1), cmap='gray')\n",
    "plt.show()\n",
    "    \n",
    "print(\"[#] Thresholding the shadow difference: \")\n",
    "plt.figure(figsize=(30, 30))\n",
    "plt.imshow(create_image_grid(out, 1) < 0, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"[#] Preprocessing the shadow difference: \")\n",
    "# thres = -0.05\n",
    "thres = 0\n",
    "inp_face = (np.array(face_image.convert(c_type))/255.0).astype(np.float32)\n",
    "tmp = [\n",
    "    out[-1] < thres,\n",
    "    out[-1] < -0.1,\n",
    "    out[-1] < -0.2,\n",
    "    \n",
    "    cv2.medianBlur(((out[-1] < thres).astype(np.uint8)), 3),\n",
    "    cv2.medianBlur(((out[-1] < thres).astype(np.uint8)), 5),\n",
    "    cv2.medianBlur(((out[-1] < thres).astype(np.uint8)), 7),\n",
    "    \n",
    "    np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0),\n",
    "    np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0),\n",
    "    np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0),\n",
    "    \n",
    "    (np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.1),\n",
    "    (np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.3),\n",
    "    (np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.5),\n",
    "                                                                             \n",
    "    (np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.7),\n",
    "    (np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.8),\n",
    "    (np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.9),\n",
    "]\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# tmp = [(np.abs(1 - (t)) * m_face) for t in tmp] # Invert the mask\n",
    "# plt.imshow(create_image_grid(tmp, 2), cmap='gray')\n",
    "# plt.show()\n",
    "tmp = [np.abs(1 - (t)) for t in tmp] # Invert the mask\n",
    "plt.figure(figsize=(15, 15))\n",
    "tmp = [(((t * ~m_glasses_and_eyes) + (1.0 * m_glasses_and_eyes)) * m_face) + (0.5 * ~m_face)  for t in tmp] # Ensure glasses area always 1\n",
    "plt.imshow(create_image_grid(tmp, 5), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process each images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_50000_to_55000', 'train_55000_to_60000']\n",
      "[#] train_50000_to_55000 => 5000/5000 => 100.00%\n",
      "[#] train_55000_to_60000 => 5000/5000 => 100.00%\n",
      "['train_0_to_5000', 'train_5000_to_10000', 'train_10000_to_15000']\n",
      "[#] train_0_to_5000 => 5000/5000 => 100.00%\n",
      "[#] train_10000_to_15000 => 5000/5000 => 100.00%\n",
      "[#] train_5000_to_10000 => 5000/5000 => 100.00%\n",
      "['train_20000_to_25000', 'train_25000_to_30000', 'train_30000_to_35000', 'train_15000_to_20000']\n",
      "[#] train_15000_to_20000 => 5000/5000 => 100.00%\n",
      "[#] train_20000_to_25000 => 5000/5000 => 100.00%\n",
      "[#] train_25000_to_30000 => 5000/5000 => 100.00%\n",
      "[#] train_30000_to_35000 => 5000/5000 => 100.00%\n",
      "['train_35000_to_40000', 'train_45000_to_50000', 'train_40000_to_45000']\n",
      "[#] train_35000_to_40000 => 5000/5000 => 100.00%\n",
      "[#] train_40000_to_45000 => 5000/5000 => 100.00%\n",
      "[#] train_45000_to_50000 => 5000/5000 => 100.00%\n",
      "[#] Total images:  60000\n"
     ]
    }
   ],
   "source": [
    "diffuse_img_path = progress(vid='11') + progress(vid='10', mothership=True) + progress(vid='9') + progress(vid='8')\n",
    "print(\"[#] Total images: \", len(diffuse_img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_shadow_diff(plot=False):\n",
    "    # for idx, path in tqdm.tqdm(enumerate(diffuse_img_path)):\n",
    "    count = 0\n",
    "    for path in tqdm.tqdm(diffuse_img_path):\n",
    "        \n",
    "        out_path = [f'/data/mint/DPM_Dataset/ffhq_256_with_anno/shadow_diff/thres_5e-2/train/',\n",
    "                    f'/data/mint/DPM_Dataset/ffhq_256_with_anno/shadow_diff/thres_1e-1/train/',\n",
    "                    f'/data/mint/DPM_Dataset/ffhq_256_with_anno/shadow_diff/median5_5e-2/train/',\n",
    "                ]\n",
    "        \n",
    "        img_name = re.findall(r\"src=\\d+\\.jpg\", path)[0].split('=')[1].split('.')[0]\n",
    "        if os.path.exists(f'{out_path[0]}/{img_name}.png') and os.path.exists(f'{out_path[1]}/{img_name}.png') and os.path.exists(f'{out_path[2]}/{img_name}.png'):\n",
    "            continue\n",
    "        face_image = Image.open(f'{image_path}/{img_name}.jpg')\n",
    "        mask_image = Image.open(f'{mask_path}/anno_{img_name}.png')\n",
    "        m_face = face_segment('faceseg_faceskin&nose&mouth&eyebrows&eyes&glasses', mask_image)\n",
    "        m_glasses_and_eyes = face_segment('faceseg_eyes&glasses', mask_image)\n",
    "        reshadow_img = [face_image] + [Image.open(f'{path}/res_frame{f}.png') for f in range(n_frames)]\n",
    "        c_type = 'L'\n",
    "        out = []\n",
    "        for i in range(len(reshadow_img)):\n",
    "            out.append(get_shadow_diff(img1=reshadow_img[i], img2=reshadow_img[0], c_type=c_type, signed=True))\n",
    "        \n",
    "        thres = -0.05\n",
    "        tmp = [\n",
    "            out[-1] < thres,\n",
    "            out[-1] < -0.1,\n",
    "            out[-1] < -0.2,\n",
    "            cv2.medianBlur(((out[-1] < thres).astype(np.uint8)), 3),\n",
    "            cv2.medianBlur(((out[-1] < thres).astype(np.uint8)), 5),\n",
    "            cv2.medianBlur(((out[-1] < thres).astype(np.uint8)), 7),\n",
    "            \n",
    "        ]\n",
    "        \n",
    "        tmp = [np.abs(1 - (t)) for t in tmp] # Invert the mask\n",
    "        tmp = [((t * ~m_glasses_and_eyes) + (1.0 * m_glasses_and_eyes))  for t in tmp] # Ensure glasses area always 1\n",
    "        tmp = [((t * m_face) + (0.5 * ~m_face)) for t in tmp] # Ensure outer face area always 0.5\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure(figsize=(30, 30))\n",
    "            plt.imshow(create_image_grid(reshadow_img, 1), cmap='gray')\n",
    "            plt.show()\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            plt.imshow(create_image_grid(tmp, 2), cmap='gray')\n",
    "            plt.show()\n",
    "            \n",
    "        out_img = [tmp[0], tmp[1], tmp[4]]\n",
    "        for op, oi in zip(out_path, out_img):\n",
    "            if not os.path.exists(op):\n",
    "                os.makedirs(op)\n",
    "            # np.save(f'{op}/{img_name}.npy', oi)\n",
    "            Image.fromarray((oi * 255).astype(np.uint8)).save(f'{op}/{img_name}.png')\n",
    "            \n",
    "        count += 1\n",
    "        # if count > 10: assert False\n",
    "save_shadow_diff(plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_shadow_futschik(plot=False):\n",
    "    # for idx, path in tqdm.tqdm(enumerate(diffuse_img_path)):\n",
    "    count = 0\n",
    "    for path in tqdm.tqdm(diffuse_img_path):\n",
    "        \n",
    "        out_path = [f'/data/mint/DPM_Dataset/ffhq_256_with_anno/shadow_diff/futschik/train/',\n",
    "                    f'/data/mint/DPM_Dataset/ffhq_256_with_anno/shadow_diff/futschik_1e-1/train/',\n",
    "                    f'/data/mint/DPM_Dataset/ffhq_256_with_anno/shadow_diff/futschik_2e-1/train/',\n",
    "        ]\n",
    "        \n",
    "        img_name = re.findall(r\"src=\\d+\\.jpg\", path)[0].split('=')[1].split('.')[0]\n",
    "        if os.path.exists(f'{out_path[0]}/{img_name}.png') and os.path.exists(f'{out_path[1]}/{img_name}.png') and os.path.exists(f'{out_path[2]}/{img_name}.png'):\n",
    "            continue\n",
    "        face_image = Image.open(f'{image_path}/{img_name}.jpg')\n",
    "        mask_image = Image.open(f'{mask_path}/anno_{img_name}.png')\n",
    "        m_face = face_segment('faceseg_faceskin&nose&mouth&eyebrows&eyes&glasses', mask_image)\n",
    "        m_glasses_and_eyes = face_segment('faceseg_eyes&glasses', mask_image)\n",
    "        reshadow_img = [face_image] + [Image.open(f'{path}/res_frame{f}.png') for f in range(n_frames)]\n",
    "        c_type = 'L'\n",
    "        out = []\n",
    "        for i in range(len(reshadow_img)):\n",
    "            out.append(get_shadow_diff(img1=reshadow_img[i], img2=reshadow_img[0], c_type=c_type, signed=True))\n",
    "        \n",
    "        inp_face = (np.array(face_image.convert(c_type))/255.0).astype(np.float32)\n",
    "        thres = -0.05\n",
    "        tmp = [\n",
    "            out[-1] < thres,\n",
    "            out[-1] < -0.1,\n",
    "            out[-1] < -0.2,\n",
    "            np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0),\n",
    "            np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.0,\n",
    "            np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.1,\n",
    "            \n",
    "            (np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.2),\n",
    "            (np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.3),\n",
    "            (np.maximum(np.minimum(1 - (inp_face)/(out[-1]+0.5 + 1e-8), 1), 0) > 0.5),\n",
    "        ]\n",
    "        \n",
    "        tmp = [np.abs(1 - (t)) for t in tmp] # Invert the mask\n",
    "        tmp = [((t * ~m_glasses_and_eyes) + (1.0 * m_glasses_and_eyes))  for t in tmp] # Ensure glasses area always 1\n",
    "        tmp = [((t * m_face) + (0.5 * ~m_face)) for t in tmp] # Ensure outer face area always 0.5\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure(figsize=(30, 30))\n",
    "            plt.imshow(create_image_grid(reshadow_img, 1), cmap='gray')\n",
    "            plt.show()\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            plt.imshow(create_image_grid(tmp, 3), cmap='gray')\n",
    "            plt.show()\n",
    "            \n",
    "        out_img = [tmp[3], tmp[5], tmp[6]]\n",
    "        for op, oi in zip(out_path, out_img):\n",
    "            if not os.path.exists(op):\n",
    "                os.makedirs(op)\n",
    "            # np.save(f'{op}/{img_name}.npy', oi)\n",
    "            Image.fromarray((oi * 255).astype(np.uint8)).save(f'{op}/{img_name}.png')\n",
    "            \n",
    "        count += 1\n",
    "        # if count > 10: assert False\n",
    "save_shadow_futschik(plot=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpm_sampling_deca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
