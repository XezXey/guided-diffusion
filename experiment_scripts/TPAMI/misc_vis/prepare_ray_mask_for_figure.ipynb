{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [11:58<00:00, 13.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import glob, tqdm, os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def face_segment(segment_part, img):\n",
    "    \n",
    "    if isinstance(img, Image.Image):\n",
    "        face_segment_anno = np.array(img)\n",
    "    else:\n",
    "        face_segment_anno = img\n",
    "        \n",
    "    bg = (face_segment_anno == 0)\n",
    "    skin = (face_segment_anno == 1)\n",
    "    l_brow = (face_segment_anno == 2)\n",
    "    r_brow = (face_segment_anno == 3)\n",
    "    l_eye = (face_segment_anno == 4)\n",
    "    r_eye = (face_segment_anno == 5)\n",
    "    eye_g = (face_segment_anno == 6)\n",
    "    l_ear = (face_segment_anno == 7)\n",
    "    r_ear = (face_segment_anno == 8)\n",
    "    ear_r = (face_segment_anno == 9)\n",
    "    nose = (face_segment_anno == 10)\n",
    "    mouth = (face_segment_anno == 11)\n",
    "    u_lip = (face_segment_anno == 12)\n",
    "    l_lip = (face_segment_anno == 13)\n",
    "    neck = (face_segment_anno == 14)\n",
    "    neck_l = (face_segment_anno == 15)\n",
    "    cloth = (face_segment_anno == 16)\n",
    "    hair = (face_segment_anno == 17)\n",
    "    hat = (face_segment_anno == 18)\n",
    "    face = np.logical_or.reduce((skin, l_brow, r_brow, l_eye, r_eye, eye_g, l_ear, r_ear, ear_r, nose, mouth, u_lip, l_lip))\n",
    "\n",
    "    if segment_part == 'faceseg_face':\n",
    "        seg_m = face\n",
    "    elif segment_part == 'faceseg_head':\n",
    "        seg_m = (face | neck | hair)\n",
    "    elif segment_part == 'faceseg_nohead':\n",
    "        seg_m = ~(face | neck | hair)\n",
    "    elif segment_part == 'faceseg_face&hair':\n",
    "        seg_m = ~bg\n",
    "    elif segment_part == 'faceseg_bg_noface&nohair':\n",
    "        seg_m = (bg | hat | neck | neck_l | cloth) \n",
    "    elif segment_part == 'faceseg_bg&ears_noface&nohair':\n",
    "        seg_m = (bg | hat | neck | neck_l | cloth) | (l_ear | r_ear | ear_r)\n",
    "    elif segment_part == 'faceseg_bg':\n",
    "        seg_m = bg\n",
    "    elif segment_part == 'faceseg_bg&noface':\n",
    "        seg_m = (bg | hair | hat | neck | neck_l | cloth)\n",
    "    elif segment_part == 'faceseg_hair':\n",
    "        seg_m = hair\n",
    "    elif segment_part == 'faceseg_faceskin':\n",
    "        seg_m = skin\n",
    "    elif segment_part == 'faceseg_faceskin&nose':\n",
    "        seg_m = (skin | nose)\n",
    "    elif segment_part == 'faceseg_eyes&glasses&mouth&eyebrows':\n",
    "        seg_m = (l_eye | r_eye | eye_g | l_brow | r_brow | mouth)\n",
    "    elif segment_part == 'faceseg_faceskin&nose&mouth&eyebrows':\n",
    "        seg_m = (skin | nose | mouth | u_lip | l_lip | l_brow | r_brow | l_eye | r_eye)\n",
    "    elif segment_part == 'faceseg_faceskin&nose&mouth&eyebrows&eyes&glasses':\n",
    "        seg_m = (skin | nose | mouth | u_lip | l_lip | l_brow | r_brow | l_eye | r_eye | eye_g)\n",
    "    elif segment_part == 'faceseg_face_noglasses':\n",
    "        seg_m = (~eye_g & face)\n",
    "    elif segment_part == 'faceseg_face_noglasses_noeyes':\n",
    "        seg_m = (~(l_eye | r_eye) & ~eye_g & face)\n",
    "    elif segment_part == 'faceseg_eyes&glasses':\n",
    "        seg_m = (l_eye | r_eye | eye_g)\n",
    "    elif segment_part == 'glasses':\n",
    "        seg_m = eye_g\n",
    "    elif segment_part == 'faceseg_eyes':\n",
    "        seg_m = (l_eye | r_eye)\n",
    "    # elif (segment_part == 'sobel_bg_mask') or (segment_part == 'laplacian_bg_mask') or (segment_part == 'sobel_bin_bg_mask'):\n",
    "    elif segment_part in ['sobel_bg_mask', 'laplacian_bg_mask', 'sobel_bin_bg_mask']:\n",
    "        seg_m = ~(face | neck | hair)\n",
    "    elif segment_part in ['canny_edge_bg_mask']:\n",
    "        seg_m = ~(face | neck | hair) | (l_ear | r_ear)\n",
    "    else: raise NotImplementedError(f\"Segment part: {segment_part} is not found!\")\n",
    "    \n",
    "    out = seg_m\n",
    "    return out\n",
    "\n",
    "\n",
    "set_ = 'valid'\n",
    "ray_mask_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/shadow_masks/{set_}/\"\n",
    "img_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/ffhq_256/{set_}/\"\n",
    "face_segment_path = f'/data/mint/DPM_Dataset/ffhq_256_with_anno/face_segment/{set_}/anno/'\n",
    "\n",
    "out_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/ray_masks/images/{set_}/\"\n",
    "out_ovl_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/ray_masks/overlays/{set_}/\"\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "os.makedirs(out_ovl_path, exist_ok=True)\n",
    "\n",
    "max_c = 8.481700287326827 # 7.383497233314015\n",
    "min_c = -4.989461058405101 # -4.985533880236826\n",
    "c_p = f'/data/mint/DPM_Dataset/ffhq_256_with_anno/params/{set_}/ffhq-{set_}-shadow-anno.txt'\n",
    "c = pd.read_csv(c_p, sep=' ', header=None, names=['image_name', 'c_val'])\n",
    "\n",
    "for i in tqdm.tqdm(sorted(glob.glob(img_path + \"*.jpg\"))):\n",
    "    # print(i)\n",
    "    img_name = i.split(\"/\")[-1]\n",
    "    face = Image.open(i)\n",
    "    face = np.array(face)\n",
    "    faceseg = Image.open(face_segment_path + 'anno_' + i.split(\"/\")[-1].replace(\".jpg\", \".png\"))\n",
    "    faceseg = face_segment('faceseg_face_noglasses_noeyes', faceseg)\n",
    "    faceseg = faceseg[..., None]\n",
    "    \n",
    "    c_val = c[c['image_name'] == img_name]['c_val'].values[0]\n",
    "    c_val_norm = (c_val - min_c)/(max_c - min_c)\n",
    "    \n",
    "    rmask = Image.open(ray_mask_path + i.split(\"/\")[-1].replace(\".jpg\", \".png\"))\n",
    "    rmask = np.array(rmask)\n",
    "    # plt.imshow(rmask)\n",
    "    # plt.show()\n",
    "    \n",
    "    # overlay = cv2.applyColorMap((shadow_area_with_c * 255).astype(np.uint8), cv2.COLORMAP_WINTER) * shadow_area\n",
    "    # plt.imshow(faceseg)\n",
    "    # plt.show()\n",
    "    # assert False\n",
    "    shadow_area = (rmask < 128) * (rmask > 0) * faceseg\n",
    "    shadow_area_with_c = shadow_area.copy() * c_val_norm\n",
    "    overlay = cv2.applyColorMap((shadow_area * 255).astype(np.uint8), cv2.COLORMAP_WINTER) * shadow_area\n",
    "    overlay = cv2.addWeighted(np.array(face), 1, overlay, 0.5, 0)\n",
    "    # plt.imshow(shadow_area * 1.0, cmap='gray')\n",
    "    # plt.show()\n",
    "    # plt.imshow(overlay)\n",
    "    # plt.show()\n",
    "    out_ovl = np.concatenate([face, (shadow_area_with_c * 255).astype(np.uint8), overlay], axis=1)\n",
    "    Image.fromarray(out_ovl).save(out_ovl_path + i.split(\"/\")[-1].replace(\".jpg\", \".png\"))\n",
    "    Image.fromarray((shadow_area_with_c * 255).astype(np.uint8)).save(out_path + i.split(\"/\")[-1].replace(\".jpg\", \".png\"))\n",
    "    # assert False\n",
    "    \n",
    "    # out_hl = [np.repeat((t[..., None]*255).astype(np.uint8), 3, axis=2) for t in out.copy()]\n",
    "    # out_hl = [cv2.applyColorMap(t, cv2.COLORMAP_WINTER) * (t==255) for t in out_hl]\n",
    "    # overlay_img = [cv2.addWeighted(np.array(face), 1, t, 0.5, 0) for t in out_hl]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpm_sampling_deca_pysh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
