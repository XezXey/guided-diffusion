{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import time\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "import sys\n",
    "sys.path.insert(0, '../../sample_scripts/')\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from sample_scripts.sample_utils.inference_utils import to_tensor\n",
    "from sample_scripts.sample_utils.vis_utils import plot_image\n",
    "from sample_scripts.sample_utils import (\n",
    "    ckpt_utils, \n",
    "    file_utils,\n",
    "    params_utils,\n",
    ")\n",
    "from guided_diffusion.dataloader.img_deca_datasets import load_data_img_deca\n",
    "\n",
    "ckpt_loader = ckpt_utils.CkptLoader(log_dir=\"Masked_Face_woclip+BgNoHead+shadow_256\", cfg_name=\"Masked_Face_woclip+BgNoHead+shadow_256.yaml\")\n",
    "cfg = ckpt_loader.cfg\n",
    "# cfg.img_cond_model.in_image = cfg.img_cond_model.in_image\n",
    "# cfg.img_cond_model.prep_image = [None, 'dilate=5', None]\n",
    "cfg.img_model.image_size = 256\n",
    "# Load dataset\n",
    "dataset = 'ffhq'\n",
    "img_dataset_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/ffhq_256/\"\n",
    "deca_dataset_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/params/\"\n",
    "# Load dataset\n",
    "if dataset == 'itw':\n",
    "    cfg.dataset.root_path = f'/data/mint/DPM_Dataset/'\n",
    "    img_dataset_path = f\"/data/mint/DPM_Dataset/ITW/itw_images_aligned/\"\n",
    "    deca_dataset_path = f\"/data/mint/DPM_Dataset/ITW/params/\"\n",
    "    img_ext = '.png'\n",
    "    cfg.dataset.training_data = 'ITW'\n",
    "    cfg.dataset.data_dir = f'{cfg.dataset.root_path}/{cfg.dataset.training_data}/itw_images_aligned/'\n",
    "elif dataset == 'ffhq':\n",
    "    cfg.dataset.root_path = f'/data/mint/DPM_Dataset/'\n",
    "    img_dataset_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/ffhq_256/\"\n",
    "    deca_dataset_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/params/\"\n",
    "    img_ext = '.jpg'\n",
    "    cfg.dataset.training_data = 'ffhq_256_with_anno'\n",
    "    cfg.dataset.data_dir = f'{cfg.dataset.root_path}/{cfg.dataset.training_data}/ffhq_256/'\n",
    "elif dataset in ['mp_valid', 'mp_test', 'mp_test2']:\n",
    "    if dataset == 'mp_test':\n",
    "        sub_f = '/MultiPIE_testset/'\n",
    "    elif dataset == 'mp_test2':\n",
    "        sub_f = '/MultiPIE_testset2/'\n",
    "    elif dataset == 'mp_valid':\n",
    "        sub_f = '/MultiPIE_validset/'\n",
    "    else: raise ValueError\n",
    "    img_dataset_path = f\"/data/mint/DPM_Dataset/MultiPIE/{sub_f}/mp_aligned/\"\n",
    "    deca_dataset_path = f\"/data/mint/DPM_Dataset/MultiPIE/{sub_f}/params/\"\n",
    "    img_ext = '.png'\n",
    "    cfg.dataset.training_data = f'/MultiPIE/{sub_f}/'\n",
    "    cfg.dataset.root_path = f'/data/mint/DPM_Dataset/'\n",
    "    cfg.dataset.data_dir = f'{cfg.dataset.root_path}/{cfg.dataset.training_data}/mp_aligned/'\n",
    "else: raise ValueError\n",
    "\n",
    "cfg.dataset.deca_dir = f'{cfg.dataset.root_path}/{cfg.dataset.training_data}/params/'\n",
    "cfg.dataset.face_segment_dir = f\"{cfg.dataset.root_path}/{cfg.dataset.training_data}/face_segment/\"\n",
    "cfg.dataset.deca_rendered_dir = f\"{cfg.dataset.root_path}/{cfg.dataset.training_data}/rendered_images/\"\n",
    "cfg.dataset.laplacian_mask_dir = f\"{cfg.dataset.root_path}/{cfg.dataset.training_data}/eyes_segment/\"\n",
    "cfg.dataset.laplacian_dir = f\"{cfg.dataset.root_path}/{cfg.dataset.training_data}/laplacian/\"\n",
    "\n",
    "loader, dataset, _ = load_data_img_deca(\n",
    "    data_dir=img_dataset_path,\n",
    "    deca_dir=deca_dataset_path,\n",
    "    batch_size=int(1e7),\n",
    "    image_size=cfg.img_model.image_size,\n",
    "    deterministic=cfg.train.deterministic,\n",
    "    augment_mode=cfg.img_model.augment_mode,\n",
    "    resize_mode=cfg.img_model.resize_mode,\n",
    "    in_image_UNet=cfg.img_model.in_image,\n",
    "    params_selector=cfg.param_model.params_selector + ['albedo'],\n",
    "    rmv_params=cfg.param_model.rmv_params,\n",
    "    set_='valid',\n",
    "    cfg=cfg,\n",
    ")\n",
    "\n",
    "from importlib import reload\n",
    "sys.path.insert(0, '../../sample_scripts/cond_utils/DECA/')\n",
    "from decalib.deca import DECA\n",
    "from decalib.datasets import datasets \n",
    "from decalib.utils import util\n",
    "from decalib.utils.config import cfg as deca_cfg\n",
    "from decalib.utils.tensor_cropper import transform_points\n",
    "\n",
    "f_mask = np.load('./FLAME_masks_face-id.pkl', allow_pickle=True, encoding='latin1')\n",
    "v_mask = np.load('./FLAME_masks.pkl', allow_pickle=True, encoding='latin1')\n",
    "img_dataset_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/ffhq_256/\"\n",
    "deca_dataset_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/params/\"\n",
    "mask={\n",
    "    'v_mask':v_mask['face'].tolist(),\n",
    "    'f_mask':f_mask['face'].tolist()\n",
    "}\n",
    "\n",
    "deca_cfg.model.extract_tex = True\n",
    "deca_cfg.rasterizer_type = 'standard'\n",
    "deca_cfg.model.use_tex = True \n",
    "deca = DECA(config = deca_cfg, device='cuda', mode='shape', mask=mask)\n",
    "\n",
    "print(deca)\n",
    "\n",
    "img_path = file_utils._list_image_files_recursively(f\"{img_dataset_path}/valid/\")\n",
    "# img_idx = file_utils.search_index_from_listpath(list_path=img_path, search=[name.split('/')[-1] for name in img_path])\n",
    "img_idx = file_utils.search_index_from_listpath(list_path=img_path, search=['60065.jpg'])\n",
    "\n",
    "dat = th.utils.data.Subset(dataset, indices=img_idx)\n",
    "subset_loader = th.utils.data.DataLoader(dat, batch_size=1,\n",
    "                                    shuffle=False, num_workers=24)\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "import tqdm\n",
    "# for _ in tqdm.tqdm(range(len(img_path))):\n",
    "subset_loader = iter(subset_loader)\n",
    "t = tqdm.trange(len(subset_loader), desc=\"Generate the shadow mask...\")\n",
    "for _ in t:\n",
    "    _, model_kwargs = next(subset_loader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
