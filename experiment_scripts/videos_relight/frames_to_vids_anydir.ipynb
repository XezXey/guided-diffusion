{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#] Loading composite images ... Done\n",
      "[#] Loading original images ... Done\n",
      "torch.Size([105, 3268, 3840, 3])\n",
      "tensor(255, dtype=torch.uint8)\n",
      "tensor(0, dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch as th\n",
    "import torchvision\n",
    "\n",
    "# open the video file\n",
    "# vid_name = './videos/Anakin_Trim_2.mp4'\n",
    "\n",
    "def sort_by_frame(path_list):\n",
    "    frame_anno = []\n",
    "    for p in path_list:\n",
    "        # frame_idx = os.path.splitext(p.split('_')[-1])[0][5:]   # 0-4 is \"frame\", so we used [5:] here\n",
    "        frame_idx = os.path.splitext(p.split('/')[-1].split('_')[-1])[0][5:]   # 0-4 is \"frame\", so we used [5:] here\n",
    "        frame_anno.append(int(frame_idx))\n",
    "    sorted_idx = np.argsort(frame_anno)\n",
    "    sorted_path_list = []\n",
    "    for idx in sorted_idx:\n",
    "      sorted_path_list.append(path_list[idx])\n",
    "    return sorted_path_list\n",
    "\n",
    "track_name = 'Anakin_2'\n",
    "composite_path = f\"/home/mint/guided-diffusion/experiment_scripts/dealignment_ffhq/videos/composite/\"\n",
    "assert os.path.exists(composite_path)\n",
    "\n",
    "print(\"[#] Loading composite images ... \", end='')\n",
    "c_fl = glob.glob(f'/{composite_path}/f*')\n",
    "c_fl = sort_by_frame(c_fl)\n",
    "c_frames = th.stack([th.tensor(np.array(Image.open(f))) for f in c_fl], dim=0)\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"[#] Loading original images ... \", end='')\n",
    "original_path = f\"/data/mint/DPM_Dataset/Videos/{track_name}/images/\"\n",
    "o_fl = [original_path + f.split('/')[-1] for f in c_fl]\n",
    "o_frames = th.stack([th.tensor(np.array(Image.open(f))) for f in o_fl], dim=0)\n",
    "print(\"Done\")\n",
    "\n",
    "# torchvision.io.write_video(video_array=c_frames, filename=f'./out.avi', fps=25, video_codec='ffv1')\n",
    "    \n",
    "all_frames_type = th.cat((o_frames, c_frames), dim=1)\n",
    "print(all_frames_type.shape)\n",
    "print(th.max(all_frames_type))\n",
    "print(th.min(all_frames_type))\n",
    "os.makedirs(f'./out/{track_name}/')\n",
    "for i, f in enumerate(c_fl):\n",
    "    torchvision.utils.save_image(tensor=(all_frames_type[i]/255.0).permute(2, 0, 1).float(), fp=f\"./out/{track_name}/comp_{f.split('/')[-1]}\")\n",
    "# torchvision.io.write_video(video_array=all_frames_type, filename=f'./combined.avi', fps=25, video_codec='ffv1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dr_conda_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
