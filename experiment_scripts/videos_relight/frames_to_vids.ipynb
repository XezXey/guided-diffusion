{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliable_light :  ['light=63502', 'light=60623_light', 'light=Denarys2_light']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch as th\n",
    "import torchvision\n",
    "\n",
    "# open the video file\n",
    "# vid_name = './videos/Anakin_Trim_2.mp4'\n",
    "\n",
    "def sort_by_frame(path_list):\n",
    "    frame_anno = []\n",
    "    for p in path_list:\n",
    "        # frame_idx = os.path.splitext(p.split('_')[-1])[0][5:]   # 0-4 is \"frame\", so we used [5:] here\n",
    "        frame_idx = os.path.splitext(p.split('/')[-1].split('_')[-1])[0][5:]   # 0-4 is \"frame\", so we used [5:] here\n",
    "        frame_anno.append(int(frame_idx))\n",
    "    sorted_idx = np.argsort(frame_anno)\n",
    "    sorted_path_list = []\n",
    "    for idx in sorted_idx:\n",
    "      sorted_path_list.append(path_list[idx])\n",
    "    return sorted_path_list\n",
    "\n",
    "track_name = 'Denarys_1'\n",
    "track_path = f\"/data/mint/sampling/Videos/log=Masked_Face_woclip+BgNoHead+shadow_256_cfg=Masked_Face_woclip+BgNoHead+shadow_256.yaml/ema_085000/valid/reverse_sampling/src={track_name}\"\n",
    "assert os.path.exists(track_path)\n",
    "\n",
    "avail_light = os.listdir(f'/{track_path}/')\n",
    "print(\"Avaliable_light : \", avail_light)\n",
    "light_file = avail_light[int(input(\"Choose light : \"))]\n",
    "relit_path = f\"{track_path}/{light_file}/diff=1000/\"\n",
    "src_path = f\"/data/mint/DPM_Dataset/Videos/{track_name}/aligned_images/valid/\"\n",
    "all_type = []\n",
    "for f_type in ['ren_f', 'ren_relit_f', 'res_f']:\n",
    "    fl = glob.glob(f'/{relit_path}/{f_type}*')\n",
    "    fl = sort_by_frame(fl)\n",
    "    if f_type == 'res_f':\n",
    "        src_f = [f\"/{src_path}/{f.split('/')[-1].split('.')[0].split('_')[-1]}.png\" for f in fl]\n",
    "        src_frames = th.stack([th.tensor(np.array(Image.open(f))) for f in src_f], dim=0)\n",
    "        all_type.append(src_frames)\n",
    "        \n",
    "    frames = th.stack([th.tensor(np.array(Image.open(f))) for f in fl], dim=0)\n",
    "    \n",
    "    all_type.append(frames)\n",
    "    torchvision.io.write_video(video_array=frames, filename=f'./{f_type}.mp4', fps=20)\n",
    "    \n",
    "all_frames_type = th.cat(all_type, dim=2)\n",
    "torchvision.io.write_video(video_array=all_frames_type, filename=f'./out_{light_file}.mp4', fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dr_conda_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
