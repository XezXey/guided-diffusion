{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import cv2\n",
    "import torchvision\n",
    "import torch as th\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import os\n",
    "\n",
    "def save_video(list_frame, name='vid'):\n",
    "    torchvision.io.write_video(f'./{name}.mp4', th.tensor(np.stack(list_frame)), fps=15)\n",
    "\n",
    "def draw_face_landmarks(image, landmarks, landmarks2=None):\n",
    "    for i, landmark in enumerate(landmarks):\n",
    "        x, y = landmark\n",
    "        cv2.circle(image, (int(x), int(y)), 10, (0, 255, 0), -1)\n",
    "        if landmarks2 is not None:\n",
    "            x2, y2 = landmarks2[i]\n",
    "            cv2.circle(image, (int(x2), int(y2)), 10, (255, 0, 0), -1)\n",
    "    return image\n",
    "\n",
    "def image_align(src_file,\n",
    "                face_landmarks,\n",
    "                output_size=1024,\n",
    "                transform_size=4096,\n",
    "                enable_padding=True):\n",
    "    # Align function from FFHQ dataset pre-processing step\n",
    "    # https://github.com/NVlabs/ffhq-dataset/blob/master/download_ffhq.py\n",
    "\n",
    "    lm = np.array(face_landmarks)\n",
    "    lm_chin = lm[0:17]  # left-right\n",
    "    lm_eyebrow_left = lm[17:22]  # left-right\n",
    "    lm_eyebrow_right = lm[22:27]  # left-right\n",
    "    lm_nose = lm[27:31]  # top-down\n",
    "    lm_nostrils = lm[31:36]  # top-down\n",
    "    lm_eye_left = lm[36:42]  # left-clockwise\n",
    "    lm_eye_right = lm[42:48]  # left-clockwise\n",
    "    lm_mouth_outer = lm[48:60]  # left-clockwise\n",
    "    lm_mouth_inner = lm[60:68]  # left-clockwise\n",
    "\n",
    "    # Calculate auxiliary vectors.\n",
    "    eye_left = np.mean(lm_eye_left, axis=0)\n",
    "    eye_right = np.mean(lm_eye_right, axis=0)\n",
    "    eye_avg = (eye_left + eye_right) * 0.5\n",
    "    eye_to_eye = eye_right - eye_left\n",
    "    mouth_left = lm_mouth_outer[0]\n",
    "    mouth_right = lm_mouth_outer[6]\n",
    "    mouth_avg = (mouth_left + mouth_right) * 0.5\n",
    "    eye_to_mouth = mouth_avg - eye_avg\n",
    "\n",
    "    # Choose oriented crop rectangle.\n",
    "    x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\n",
    "    x /= np.hypot(*x)\n",
    "    x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
    "    y = np.flipud(x) * [-1, 1]\n",
    "    c = eye_avg + eye_to_mouth * 0.1\n",
    "    quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n",
    "    qsize = np.hypot(*x) * 2\n",
    "\n",
    "    # Load in-the-wild image.\n",
    "    if not os.path.isfile(src_file):\n",
    "        print(\n",
    "            '\\nCannot find source image. Please run \"--wilds\" before \"--align\".'\n",
    "        )\n",
    "        return\n",
    "    img = PIL.Image.open(src_file)\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    # Shrink.\n",
    "    shrink = int(np.floor(qsize / output_size * 0.5))\n",
    "    if shrink > 1:\n",
    "        rsize = (int(np.rint(float(img.size[0]) / shrink)),\n",
    "                 int(np.rint(float(img.size[1]) / shrink)))\n",
    "        img = img.resize(rsize, PIL.Image.ANTIALIAS)\n",
    "        quad /= shrink\n",
    "        qsize /= shrink\n",
    "\n",
    "    # Crop.\n",
    "    border = max(int(np.rint(qsize * 0.1)), 3)\n",
    "    crop = (int(np.floor(min(quad[:, 0]))), int(np.floor(min(quad[:, 1]))),\n",
    "            int(np.ceil(max(quad[:, 0]))), int(np.ceil(max(quad[:, 1]))))\n",
    "    crop = (max(crop[0] - border, 0), max(crop[1] - border, 0),\n",
    "            min(crop[2] + border,\n",
    "                img.size[0]), min(crop[3] + border, img.size[1]))\n",
    "    if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n",
    "        img = img.crop(crop)\n",
    "        quad -= crop[0:2]\n",
    "\n",
    "    # Pad.\n",
    "    pad = (int(np.floor(min(quad[:, 0]))), int(np.floor(min(quad[:, 1]))),\n",
    "           int(np.ceil(max(quad[:, 0]))), int(np.ceil(max(quad[:, 1]))))\n",
    "    pad = (max(-pad[0] + border,\n",
    "               0), max(-pad[1] + border,\n",
    "                       0), max(pad[2] - img.size[0] + border,\n",
    "                               0), max(pad[3] - img.size[1] + border, 0))\n",
    "    if enable_padding and max(pad) > border - 4:\n",
    "        pad = np.maximum(pad, int(np.rint(qsize * 0.3)))\n",
    "        img = np.pad(np.float32(img),\n",
    "                     ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n",
    "        h, w, _ = img.shape\n",
    "        y, x, _ = np.ogrid[:h, :w, :1]\n",
    "        mask = np.maximum(\n",
    "            1.0 -\n",
    "            np.minimum(np.float32(x) / pad[0],\n",
    "                       np.float32(w - 1 - x) / pad[2]), 1.0 -\n",
    "            np.minimum(np.float32(y) / pad[1],\n",
    "                       np.float32(h - 1 - y) / pad[3]))\n",
    "        blur = qsize * 0.02\n",
    "        img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) -\n",
    "                img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n",
    "        img += (np.median(img, axis=(0, 1)) - img) * np.clip(mask, 0.0, 1.0)\n",
    "        img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), 0, 255)),\n",
    "                                  'RGB')\n",
    "        quad += pad[:2]\n",
    "\n",
    "    # Transform.\n",
    "    img = img.transform((transform_size, transform_size), PIL.Image.QUAD,\n",
    "                        (quad + 0.5).flatten(), PIL.Image.BILINEAR)\n",
    "    if output_size < transform_size:\n",
    "        img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/mint/DPM_Dataset/Videos/joker_3/images/'\n",
    "kpts = np.load('./joker_3_align_params.npy', allow_pickle=True).item()\n",
    "frames = sorted(kpts.keys(), key=lambda x:int(x[5:-4]))\n",
    "kpts_vis = []\n",
    "for f in frames:\n",
    "    img = np.array(Image.open(data_dir + f))\n",
    "    lmk = draw_face_landmarks(img, kpts[f]['face_landmark'])\n",
    "    kpts_vis.append(lmk)\n",
    "    \n",
    "save_video(kpts_vis, name='lmk')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning function given Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/mint/DPM_Dataset/Videos/joker_2/images/'\n",
    "kpts = np.load('./joker_2_align_params.npy', allow_pickle=True).item()\n",
    "frames = sorted(kpts.keys(), key=lambda x:int(x[5:-4]))\n",
    "aligned_vis = []\n",
    "for f in frames:\n",
    "    aligned_img = image_align(src_file=data_dir + f,\n",
    "                              face_landmarks=kpts[f]['face_landmark'], \n",
    "                              output_size=256)\n",
    "    aligned_vis.append(aligned_img)\n",
    "    \n",
    "save_video(aligned_vis, name='aligned')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical flow on face landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 68, 2) (141, 68, 2)\n",
      "(142, 68, 2)\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/data/mint/DPM_Dataset/Videos/joker_3/images/'\n",
    "kpts = np.load('./joker_3_align_params.npy', allow_pickle=True).item()\n",
    "frames = sorted(kpts.keys(), key=lambda x:int(x[5:-4]))\n",
    "all_kpts = []\n",
    "for f in frames:\n",
    "    all_kpts.append(kpts[f]['face_landmark'])\n",
    "all_kpts = np.stack(all_kpts)   # T x #N-points x 2\n",
    "\n",
    "def compute_flow(kpts):\n",
    "    fw_flows = kpts[1:] - kpts[:-1]\n",
    "    bw_flows = (kpts[::-1][1:] - kpts[::-1][:-1])[::-1]\n",
    "    print(fw_flows.shape, bw_flows.shape)\n",
    "    return fw_flows, bw_flows\n",
    "\n",
    "def flow_smooth_kpts(kpts, n=2):\n",
    "    fw_flows, bw_flows = compute_flow(kpts)\n",
    "    smooth_kpts = []\n",
    "    for i, kpt in enumerate(kpts):\n",
    "        fw_idx = np.clip(i+n, 0, kpts.shape[0])\n",
    "        bw_idx = np.clip(i-n, 0, kpts.shape[0])\n",
    "        \n",
    "        # Kpts\n",
    "        fw_kpt = kpts[i:fw_idx]\n",
    "        bw_kpt = kpts[bw_idx:i]\n",
    "        \n",
    "        # Flows\n",
    "        fw_flow = fw_flows[i:fw_idx]\n",
    "        bw_flow = fw_flows[bw_idx:i]\n",
    "        # print(i, fw_kpt.shape, bw_kpt.shape, fw_flow.shape, bw_flow.shape)\n",
    "\n",
    "\n",
    "        candidate = [kpt]\n",
    "        for j in range(fw_flow.shape[0]):\n",
    "            candidate.append(fw_kpt[j] + (np.sum(fw_flow[j:], axis=0)))\n",
    "            \n",
    "        for j in range(bw_flow.shape[0]):\n",
    "            candidate.append(bw_kpt[j] + (np.sum(bw_flow[j:], axis=0)))\n",
    "    \n",
    "        candidate = np.stack(candidate)\n",
    "        smooth_kpts.append(np.mean(candidate, axis=0))\n",
    "    return np.stack(smooth_kpts)\n",
    "    \n",
    "smooth_kpts = flow_smooth_kpts(all_kpts, n=5)\n",
    "print(smooth_kpts.shape)\n",
    "\n",
    "kpts_vis = []\n",
    "for i, f in enumerate(frames):\n",
    "    img = np.array(Image.open(data_dir + f))\n",
    "    lmk = draw_face_landmarks(img, kpts[f]['face_landmark'], smooth_kpts[i])\n",
    "    kpts_vis.append(lmk)\n",
    "    \n",
    "save_video(kpts_vis, name='smooth_lmk')\n",
    "\n",
    "\n",
    "aligned_vis = []\n",
    "for i, f in enumerate(frames):\n",
    "    aligned_img = image_align(src_file=data_dir + f,\n",
    "                              face_landmarks=smooth_kpts[i], \n",
    "                              output_size=256)\n",
    "    aligned_vis.append(aligned_img)\n",
    "    \n",
    "save_video(aligned_vis, name='smooth_aligned')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpm_sampling_deca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
