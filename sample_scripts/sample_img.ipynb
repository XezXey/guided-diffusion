{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image sample (DDPM - guided diffusion - Diffusion beats gans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function \n",
    "import argparse\n",
    "import os, sys, glob\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0, 1, 2, 3\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as th\n",
    "import PIL\n",
    "import pytorch_lightning as pl\n",
    "sys.path.insert(0, '../')\n",
    "from guided_diffusion.script_util import (\n",
    "    seed_all,\n",
    ")\n",
    "import importlib\n",
    "\n",
    "# Sample utils\n",
    "from sample_utils import ckpt_utils, params_utils, vis_utils, file_utils, img_utils, inference_utils\n",
    "importlib.reload(ckpt_utils)\n",
    "importlib.reload(params_utils)\n",
    "importlib.reload(vis_utils)\n",
    "importlib.reload(file_utils)\n",
    "importlib.reload(img_utils)\n",
    "importlib.reload(inference_utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings \n",
    "\n",
    "# List model_logs\n",
    "# cfg_name = \"cond_img64_by_deca_arcface.yaml\"\n",
    "# log_dir = \"img64_cond_by_deca_arcface\"\n",
    "# cfg_name = \"imgsize_64_condition.yaml\"\n",
    "# log_dir = \"imgsize_64_condition\"\n",
    "cfg_name = \"cond_img64_by_deca_arcface.yaml\"\n",
    "log_dir = \"cond_img64_by_deca_arcface\"\n",
    "set_ = \"valid\"\n",
    "\n",
    "step = \"100000\"\n",
    "ckpt_selector = \"ema\"\n",
    "ckpt_loader = ckpt_utils.CkptLoader(log_dir=log_dir, cfg_name=cfg_name)\n",
    "cfg = ckpt_loader.cfg\n",
    "img_model, diffusion = ckpt_loader.load_model(ckpt_selector=ckpt_selector, step=step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load params\n",
    "params_key = ['shape', 'pose', 'exp', 'cam', 'light', 'faceemb']\n",
    "params_train, params_train_arr = params_utils.load_params(path=\"/data/mint/ffhq_256_with_anno/params/train/\", params_key=params_key)\n",
    "params_valid, params_valid_arr = params_utils.load_params(path=\"/data/mint/ffhq_256_with_anno/params/valid/\", params_key=params_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image for condition (if needed)\n",
    "img_dataset_path = f'/data/mint/ffhq_256_with_anno/ffhq_256/{set_}/'\n",
    "all_files = file_utils._list_image_files_recursively(img_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "base_idx = 12\n",
    "mode = {'init_noise':'fixed_noise', 'cond_params':'vary_cond'}\n",
    "interchange=['pose']\n",
    "\n",
    "if set_ == 'train':\n",
    "    params_set = params_train\n",
    "elif set_ == 'valid':\n",
    "    params_set = params_valid\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "seed_all(23)\n",
    "im = inference_utils.InputManipulate(cfg=cfg, params=params_set, batch_size=batch_size)\n",
    "init_noise, model_kwargs = im.prep_model_input(params_set=params_set, mode=mode, interchange=interchange, base_idx=base_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_inference = inference_utils.PLSampling(img_model=img_model, diffusion=diffusion, cfg=cfg, sample_fn=diffusion.ddim_sample_loop)\n",
    "sample_ddim = pl_inference(noise=init_noise, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_utils.plot_sample(img=sample_ddim['img_output'])\n",
    "src_img_list, render_img_list = im.get_image(model_kwargs=model_kwargs, params=params_set, img_dataset_path=img_dataset_path)\n",
    "src_img = th.cat(src_img_list, dim=0)\n",
    "render_img = th.cat(render_img_list, dim=0)\n",
    "vis_utils.plot_sample(img=src_img, render_img=render_img, sampling_img=sample_ddim['img_output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-the-wild Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-the-wild Image\n",
    "import torch as th\n",
    "import sys, os\n",
    "\n",
    "sys.path.insert(0, './cond_utils/arcface/')\n",
    "sys.path.insert(0, './cond_utils/arcface/detector/')\n",
    "sys.path.insert(0, './cond_utils/deca/')\n",
    "from cond_utils.arcface import get_arcface_emb\n",
    "from cond_utils.deca import get_deca_emb\n",
    "itw_path = \"./itw_images/\"\n",
    "device = 'cuda:2'\n",
    "\n",
    "# ArcFace\n",
    "faceemb_itw, emb = get_arcface_emb.get_arcface_emb(img_path=itw_path, device=device)\n",
    "\n",
    "# DECA\n",
    "params_dict = {'shape':100, 'pose':6, 'exp':50, 'cam':3, 'light':27, 'faceemb':512,}\n",
    "deca_itw = get_deca_emb.get_deca_emb(img_path=itw_path, device=device)\n",
    "\n",
    "assert deca_itw.keys() == faceemb_itw.keys()\n",
    "params_itw = {}\n",
    "for img_name in deca_itw.keys():\n",
    "    params_itw[img_name] = deca_itw[img_name]\n",
    "    params_itw[img_name].update(faceemb_itw[img_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(params_itw)\n",
    "seed_all(47)\n",
    "base_idx = 3\n",
    "itw_mode = {'init_noise':'fixed_noise', 'cond_params':'vary_cond'}\n",
    "\n",
    "im_itw = inference_utils.InputManipulate(cfg=cfg, params=params_itw, batch_size=batch_size, sorted=True)\n",
    "itw_noise = im_itw.get_init_noise(mode=mode['init_noise'], img_size=cfg.img_model.image_size)\n",
    "itw_kwargs = im_itw.load_condition(params=params_itw)\n",
    "\n",
    "itw_src_img_list = []\n",
    "for img_name in itw_kwargs['image_name']:\n",
    "    itw_src_img = PIL.Image.open(itw_path + img_name).resize((cfg.img_model.image_size, cfg.img_model.image_size))\n",
    "    itw_src_img = (th.tensor(np.transpose(itw_src_img, (2, 0, 1)))[None, :] / 127.5) - 1\n",
    "    itw_src_img_list.append(itw_src_img)\n",
    "\n",
    "itw_src_img = th.cat(itw_src_img_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interchange the condition\n",
    "itw_kwargs['cond_params'] = im_itw.interchange_condition(interchange=['pose'], base_idx=base_idx, cond_params=itw_kwargs['cond_params'])\n",
    "\n",
    "# Sampling\n",
    "pl_inference = inference_utils.PLSampling(img_model=img_model, diffusion=diffusion, cfg=cfg, sample_fn=diffusion.ddim_sample_loop)\n",
    "itw_sample_ddim = pl_inference(noise=itw_noise, model_kwargs=itw_kwargs)\n",
    "vis_utils.plot_sample(img=itw_src_img, sampling_img=itw_sample_ddim['img_output'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDIM Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itw_path = \"./itw_images/\"\n",
    "device = 'cuda:0'\n",
    "base_idx = 3\n",
    "all_itw_files = file_utils._list_image_files_recursively(itw_path)\n",
    "itw_images = th.tensor(np.stack([img_utils.prep_images(all_itw_files[i], cfg.img_model.image_size) for i in range(len(all_itw_files))], axis=0)).to(device)\n",
    "\n",
    "im_itw = inference_utils.InputManipulate(cfg=cfg, params=params_itw, batch_size=len(params_itw), sorted=True)\n",
    "itw_kwargs = im_itw.load_condition(params=params_itw)\n",
    "itw_kwargs['cond_params'] = itw_kwargs['cond_params'].to(device)\n",
    "\n",
    "# Reverse\n",
    "# pl_reverse_sampling = inference_utils.PLReverseSampling(img_model=img_model, diffusion=diffusion, sample_fn=diffusion.ddim_reverse_sample_loop, cfg=cfg)\n",
    "pl_reverse_sampling = inference_utils.PLReverseSampling(img_model=img_model, diffusion=diffusion, sample_fn=diffusion.q_sample, cfg=cfg)\n",
    "reverse_ddim_sample = pl_reverse_sampling(x=itw_images, model_kwargs=itw_kwargs)\n",
    "\n",
    "# Forward\n",
    "itw_kwargs['cond_params'] = im_itw.interchange_condition(interchange=['pose'], base_idx=base_idx, cond_params=itw_kwargs['cond_params'])\n",
    "\n",
    "pl_sampling = inference_utils.PLSampling(img_model=img_model, diffusion=diffusion, sample_fn=diffusion.ddim_sample_loop, cfg=cfg)\n",
    "sample_ddim = pl_sampling(noise=reverse_ddim_sample['img_output'], model_kwargs=itw_kwargs)\n",
    "vis_utils.plot_sample(img=itw_images, reverse_sampling_images=reverse_ddim_sample['img_output'], sampling_img=sample_ddim['img_output'])\n",
    "\n",
    "\n",
    "# interchange = ['pose']\n",
    "# mode = {'init_noise':'fixed_noise', 'cond_params':'vary_cond'}\n",
    "# # Interchange the condition\n",
    "# itw_kwargs = get_cond_params(batch_size=len(r_idx), mode=mode['cond_params'], interchange=interchange, r_idx=r_idx, base_idx=base_idx, model_kwargs=itw_kwargs)\n",
    "# pl_sampling = PLSampling(img_model=img_model, sample_fn=diffusion.ddim_sample_loop)\n",
    "# sample_ddim = pl_sampling(noise=th.cat([reverse_ddim_sample['img_output'][[base_idx]]] * len(r_idx), dim=0), model_kwargs=itw_kwargs)\n",
    "# vis_utils.plot_sample(img=itw_images, reverse_sampling_images=reverse_ddim_sample['img_output'], sampling_img=sample_ddim['img_output'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In-the-wild Image\n",
    "import torch as th\n",
    "import sys, os\n",
    "\n",
    "import blobfile as bf\n",
    "sys.path.insert(0, './cond_utils/arcface/')\n",
    "sys.path.insert(0, './cond_utils/arcface/detector/')\n",
    "sys.path.insert(0, './cond_utils/deca/')\n",
    "from cond_utils.arcface import get_arcface_emb\n",
    "from cond_utils.deca import get_deca_emb\n",
    "import cv2\n",
    "\n",
    "itw_path = \"/home/mint/guided-diffusion/sample_scripts/itw_videos/\"\n",
    "itw_path = file_utils._list_video_files_recursively(itw_path)\n",
    "device = 'cuda:2'\n",
    "\n",
    "for vid in itw_path:\n",
    "    _ = img_utils.video2sequence(vid)\n",
    "\n",
    "video_name = \"-7TMJtnhiPM_0000_S1202_E1607_L345_T26_R857_B538\" \n",
    "img_path = f\"/home/mint/guided-diffusion/sample_scripts/itw_videos/cropped_clips/{video_name}/\"\n",
    "\n",
    "params_dict = {'shape':100, 'pose':6, 'exp':50, 'cam':3, 'light':27, 'faceemb':512,}\n",
    "deca_itw = get_deca_emb.get_deca_emb(img_path=img_path, device=device, vis=False)\n",
    "\n",
    "# ArcFace\n",
    "faceemb_itw, emb = get_arcface_emb.get_arcface_emb(img_path=img_path, device=device)\n",
    "\n",
    "assert deca_itw.keys() == faceemb_itw.keys()\n",
    "params_itw = {}\n",
    "for img_name in deca_itw.keys():\n",
    "    params_itw[img_name] = deca_itw[img_name]\n",
    "    params_itw[img_name].update(faceemb_itw[img_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(img_utils)\n",
    "im_itw = inference_utils.InputManipulate(cfg=cfg, params=params_itw, batch_size=len(params_itw), sorted=True)\n",
    "itw_kwargs = {}\n",
    "itw_kwargs = im_itw.load_condition(params=params_itw)\n",
    "src_img_list = []\n",
    "for img_name in itw_kwargs['image_name']:\n",
    "    src_img = PIL.Image.open(img_path + img_name).resize((cfg.img_model.image_size, cfg.img_model.image_size))\n",
    "    src_img = src_img.convert('RGB')\n",
    "    src_img = np.array(src_img)\n",
    "    src_img = (np.transpose(src_img, (2, 0, 1)) / 127.5) - 1\n",
    "    src_img_list.append(src_img)\n",
    "\n",
    "img_utils.sequence2gif(src_img_list, img_size=cfg.img_model.image_size, save_fn='src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(inference_utils)\n",
    "interchange = ['pose']\n",
    "mode = {'init_noise':'fixed_noise', 'cond_params':'vary_cond'}\n",
    "base_idx = 12\n",
    "# Interchange the condition\n",
    "src_cond_params = im_itw.get_cond_params(mode=mode['cond_params'], base_idx=base_idx, params_set=params_valid)\n",
    "merged_cond_params = inference_utils.merge_cond(src_cond_params=src_cond_params['cond_params'][[base_idx]], dst_cond_params=itw_kwargs['cond_params'])\n",
    "\n",
    "itw_kwargs_merged = itw_kwargs.copy()\n",
    "itw_kwargs_merged['cond_params'] = merged_cond_params\n",
    "\n",
    "im_itw_ = inference_utils.InputManipulate(cfg=cfg, params=merged_cond_params, batch_size=itw_kwargs_merged['cond_params'].shape[0], sorted=True)\n",
    "itw_kwargs_merged['cond_params'] = im_itw_.interchange_condition(cond_params=itw_kwargs_merged['cond_params'], interchange=['pose'], base_idx=0)\n",
    "itw_noise = im_itw_.get_init_noise(mode=mode['init_noise'], img_size=cfg.img_model.image_size)\n",
    "\n",
    "pl_sampling = inference_utils.PLSampling(img_model=img_model, diffusion=diffusion, sample_fn=diffusion.ddim_sample_loop, cfg=cfg)\n",
    "\n",
    "all_frames = []\n",
    "sub_batch = 100\n",
    "n_frames = range(itw_noise.shape[0])\n",
    "sep = [n_frames[i:i+sub_batch] for i in range(0, len(n_frames), sub_batch)]\n",
    "for sub_idx in sep:\n",
    "    print(\"Frame : \", sub_idx)\n",
    "    sub_noise = itw_noise[sub_idx]\n",
    "    sub_kwargs = {'cond_params':itw_kwargs_merged['cond_params'][sub_idx]}\n",
    "    sample_ddim = pl_sampling(noise=sub_noise, model_kwargs=sub_kwargs)\n",
    "    all_frames.append(sample_ddim['img_output'].detach().cpu().numpy())\n",
    "\n",
    "all_frames = list(np.concatenate(all_frames))\n",
    "img_utils.sequence2gif(imgs=all_frames, img_size=cfg.img_model.image_size, save_fn=f'sj{base_idx}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
