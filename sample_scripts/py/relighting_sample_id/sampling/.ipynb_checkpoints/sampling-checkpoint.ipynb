{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "# Dataset\n",
    "parser.add_argument('--set', type=str, default='valid')\n",
    "# Model/Config\n",
    "parser.add_argument('--step', type=str, default='050000')\n",
    "parser.add_argument('--ckpt_selector', type=str, default='ema')\n",
    "parser.add_argument('--cfg_name', type=str, default=None)\n",
    "parser.add_argument('--log_dir', type=str, default=None)\n",
    "# Interpolation\n",
    "parser.add_argument('--interpolate', nargs='+', default=None)\n",
    "parser.add_argument('--interpolate_step', type=int, default=15)\n",
    "parser.add_argument('--interpolate_noise', action='store_true', default=False)\n",
    "parser.add_argument('--lerp', action='store_true', default=False)\n",
    "parser.add_argument('--slerp', action='store_true', default=False)\n",
    "parser.add_argument('--uncond_sampling', action='store_true', default=False)\n",
    "parser.add_argument('--uncond_sampling_iters', type=int, default=1)\n",
    "parser.add_argument('--reverse_sampling', action='store_true', default=False)\n",
    "parser.add_argument('--separate_reverse_sampling', action='store_true', default=False)\n",
    "# Samples selection\n",
    "parser.add_argument('--n_subject', type=int, default=-1)\n",
    "parser.add_argument('--sample_pair_json', type=str, default=None)\n",
    "parser.add_argument('--sample_pair_mode', type=str, default=None)\n",
    "parser.add_argument('--src_dst', nargs='+', default=[])\n",
    "# Pertubation the image condition\n",
    "parser.add_argument('--perturb_img_cond', action='store_true', default=False)\n",
    "parser.add_argument('--perturb_mode', type=str, default='zero')\n",
    "parser.add_argument('--perturb_where', nargs='+', default=[])\n",
    "\n",
    "# Rendering\n",
    "parser.add_argument('--render_mode', type=str, default=\"shape\")\n",
    "parser.add_argument('--rotate_normals', action='store_true', default=False)\n",
    "# Diffusion\n",
    "parser.add_argument('--diffusion_steps', type=int, default=1000)\n",
    "parser.add_argument('--denoised_clamp', type=float, default=None)\n",
    "# Misc.\n",
    "parser.add_argument('--seed', type=int, default=23)\n",
    "parser.add_argument('--gpu_id', type=str, default=\"0\")\n",
    "parser.add_argument('--save_intermediate', action='store_true', default=False)\n",
    "parser.add_argument('--postfix', type=str, default='')\n",
    "parser.add_argument('--ovr_img', type=str, default=None)\n",
    "parser.add_argument('--ovr_mod', action='store_true', default=False)\n",
    "parser.add_argument('--norm_img', action='store_true', default=False)\n",
    "parser.add_argument('--use_global_norm', action='store_true', default=False)\n",
    "parser.add_argument('--norm_space', type=str, default='rgb')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "import os, sys, glob\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as th\n",
    "import PIL, cv2\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "sys.path.insert(0, '../../../')\n",
    "from guided_diffusion.script_util import (\n",
    "    seed_all,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "from guided_diffusion.dataloader.img_deca_datasets import load_data_img_deca\n",
    "\n",
    "# Sample utils\n",
    "sys.path.insert(0, '../../')\n",
    "from sample_utils import (\n",
    "    ckpt_utils, \n",
    "    params_utils, \n",
    "    vis_utils, \n",
    "    file_utils, \n",
    "    inference_utils, \n",
    "    mani_utils,\n",
    ")\n",
    "device = 'cuda' if th.cuda.is_available() and th._C._cuda_getDeviceCount() > 0 else 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#] Model Path : \n",
      "#0 : /data/mint/model_logs_mount/v10/original_dpm/\n",
      "[#] Config Path :  ['/home/mint/guided-diffusion/config/CVPRs/Original_DPM/original_dpm.yaml']\n",
      "Merging with :  Namespace(cfg='/home/mint/guided-diffusion/config/CVPRs/Original_DPM/original_dpm.yaml')\n",
      "\n",
      "[#] Sampling with diffusion_steps = 1000\n",
      "[#] Available ckpt :  ['_000000.pt', '_010000.pt', '_020000.pt', '_030000.pt', '_040000.pt', '_050000.pt', '_060000.pt', '_070000.pt', '_080000.pt', '_090000.pt', '_100000.pt', '_110000.pt', '_120000.pt', '_130000.pt', '_140000.pt', '_150000.pt', '_160000.pt', '_170000.pt', '_180000.pt', '_190000.pt', '_200000.pt', '_210000.pt', '_220000.pt', '_230000.pt']\n",
      "[#] Loading.../data/mint/model_logs_mount/v10/original_dpm//ImgCond_ema_0.9999_050000.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading deca params...: 100%|███████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#] Bounding the input of UNet to +-1.0\n",
      "[#] Parameters Conditioning\n",
      "Params keys order :  []\n",
      "Remove keys :  []\n",
      "Image condition :  ['raw']\n",
      "DPM Image condition :  [None]\n"
     ]
    }
   ],
   "source": [
    "seed_all(47)\n",
    "\n",
    "################ SETTINGS ################\n",
    "args.cfg_name = \"original_dpm.yaml\"\n",
    "args.log_dir = \"original_dpm\"\n",
    "args.step = '050000'\n",
    "args.ckpt_selector = 'ema'\n",
    "args.set = 'valid'\n",
    "args.sample_pair_json = './sample_json/ipynb_samples.json'\n",
    "args.sample_pair_mode = 'pair'\n",
    "\n",
    "# Load Ckpt\n",
    "if args.cfg_name is None:\n",
    "    args.cfg_name = args.log_dir + '.yaml'\n",
    "ckpt_loader = ckpt_utils.CkptLoader(log_dir=args.log_dir, cfg_name=args.cfg_name)\n",
    "cfg = ckpt_loader.cfg\n",
    "\n",
    "print(f\"[#] Sampling with diffusion_steps = {args.diffusion_steps}\")\n",
    "cfg.diffusion.diffusion_steps = args.diffusion_steps\n",
    "model_dict, diffusion = ckpt_loader.load_model(ckpt_selector=args.ckpt_selector, step=args.step)\n",
    "model_dict = inference_utils.eval_mode(model_dict)\n",
    "\n",
    "# Load dataset\n",
    "if args.set == 'itw':\n",
    "    img_dataset_path = \"../../itw_images/aligned/\"\n",
    "    deca_dataset_path = None\n",
    "elif args.set == 'train' or args.set == 'valid':\n",
    "    img_dataset_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/ffhq_256/\"\n",
    "    deca_dataset_path = f\"/data/mint/DPM_Dataset/ffhq_256_with_anno/params/\"\n",
    "else: raise NotImplementedError\n",
    "\n",
    "loader, dataset, avg_dict = load_data_img_deca(\n",
    "    data_dir=img_dataset_path,\n",
    "    deca_dir=deca_dataset_path,\n",
    "    batch_size=int(1e7),\n",
    "    image_size=cfg.img_model.image_size,\n",
    "    deterministic=cfg.train.deterministic,\n",
    "    augment_mode=cfg.img_model.augment_mode,\n",
    "    resize_mode=cfg.img_model.resize_mode,\n",
    "    in_image_UNet=cfg.img_model.in_image,\n",
    "    params_selector=cfg.param_model.params_selector,\n",
    "    rmv_params=cfg.param_model.rmv_params,\n",
    "    set_=args.set,\n",
    "    cfg=cfg,\n",
    "    mode='sampling'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = dataset.__len__()\n",
    "img_path = file_utils._list_image_files_recursively(f\"{img_dataset_path}/{args.set}\")\n",
    "\n",
    "# DECA Rendering\n",
    "# if np.any(['deca_masked' in n for n in list(filter(None, dataset.condition_image))]):\n",
    "#     mask = params_utils.load_flame_mask()\n",
    "# else: \n",
    "#     mask=None\n",
    "# deca_obj = params_utils.init_deca(mask=mask)\n",
    "\n",
    "denoised_fn = None\n",
    "pl_sampling = inference_utils.PLSampling(model_dict=model_dict, \n",
    "                                            diffusion=diffusion, \n",
    "                                            reverse_fn=diffusion.ddim_reverse_sample_loop, \n",
    "                                            forward_fn=diffusion.ddim_sample_loop,\n",
    "                                            denoised_fn=denoised_fn,\n",
    "                                            cfg=cfg,\n",
    "                                            args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inversion(dat, idx, use_global_norm, norm_img, model_kwargs, norm_space='gray'):\n",
    "    '''\n",
    "    :param dat: images in B x C x H x W\n",
    "    '''\n",
    "    dat = dat[[idx]]\n",
    "    model_kwargs['use_cond_xt_fn'] = False\n",
    "    model_kwargs['dpm_cond_img'] = None \n",
    "    cond = copy.deepcopy(model_kwargs)\n",
    "    if norm_img:\n",
    "        print(f\"[#] Normalize image in {norm_space}...\")\n",
    "        def rgb_to_gray(img):\n",
    "            out = (img[[0], [[0]], ...] * 0.2989) + (img[[0], [[1]], ...] * 0.5870) + (img[[0], [[2]], ...] * 0.1140)\n",
    "            return out\n",
    "        assert args.norm_space in ['gray', 'rgb']\n",
    "        if args.norm_space == 'gray':\n",
    "            gray_img = rgb_to_gray(dat)\n",
    "            std_img, mu_img = th.std_mean(gray_img)\n",
    "            mu_gray_dataset, std_gray_dataset = 114.49997340551313, 58.050383371049826\n",
    "            mu_gray_dataset = (mu_gray_dataset/127.5) - 1\n",
    "            std_gray_dataset = (std_gray_dataset/127.5)\n",
    "            mu_dataset = mu_gray_dataset\n",
    "            std_dataset = std_gray_dataset\n",
    "        elif args.norm_space == 'rgb':\n",
    "            std_img, mu_img = th.std_mean(dat)\n",
    "            mu_rgb_dataset, std_rgb_dataset = 112.82840539423624, 62.779011111637864\n",
    "            mu_rgb_dataset = (mu_rgb_dataset/127.5) - 1\n",
    "            std_rgb_dataset = (std_rgb_dataset/127.5)\n",
    "            mu_dataset = mu_rgb_dataset\n",
    "            std_dataset = std_rgb_dataset\n",
    "        else: raise ValueError(f\"[#] Invalid : {args.norm_space}\")\n",
    "        \n",
    "        img = (dat - mu_img) / std_img\n",
    "        print(f\"Local Normalization factor(mu, std) : {mu_img}, {std_img}\")\n",
    "        if use_global_norm:\n",
    "            print(\"[#] Using global norm...\")\n",
    "            print(f\"Global Normalization factor(mu, std) : {mu_dataset}, {std_dataset}\")\n",
    "            img = (img * std_dataset) + mu_dataset\n",
    "     \n",
    "    # Reverse   \n",
    "    reverse_ddim_sample = pl_sampling.reverse_proc(x=img, model_kwargs=cond, store_intermediate=False)\n",
    "    noise_map = reverse_ddim_sample['final_output']['sample']\n",
    "    # Forward   \n",
    "    sample_ddim = pl_sampling.forward_proc(noise=noise_map, model_kwargs=cond, store_intermediate=False)\n",
    "    \n",
    "    if norm_img:\n",
    "        # Denormalize\n",
    "        print(\"[#] DeNormalize image...\")\n",
    "        if use_global_norm:\n",
    "            print(\"[#] Global DeNormalizing...\")\n",
    "            sample_ddim['final_output']['sample'] = (sample_ddim['final_output']['sample'] - mu_dataset) / std_dataset\n",
    "            sample_ddim['final_output']['pred_xstart'] = (sample_ddim['final_output']['pred_xstart'] - mu_dataset) / std_dataset\n",
    "        sample_ddim['final_output']['sample'] = (sample_ddim['final_output']['sample'] * std_img) + mu_img\n",
    "        sample_ddim['final_output']['pred_xstart'] = (sample_ddim['final_output']['pred_xstart'] * std_img) + mu_img\n",
    "        \n",
    "    sample_frames = vis_utils.convert2rgb(sample_ddim['final_output']['sample'], cfg.img_model.input_bound) / 255.0\n",
    "    \n",
    "    return sample_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [#] Sampling is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#] Normalize image in gray...\n",
      "Local Normalization factor(mu, std) : -0.4669653799019606, 0.42625438869644694\n",
      "[#] Using global norm...\n",
      "Global Normalization factor(mu, std) : -0.11507133024128435, 0.4923844008755911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77af0d9edc1f4b2caccd370ded7f4220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_img_idx, all_img_name, args.n_subject = mani_utils.get_samples_list(args.sample_pair_json, \n",
    "                                                                        args.sample_pair_mode, \n",
    "                                                                        args.src_dst, img_path, \n",
    "                                                                        args.n_subject)\n",
    "\n",
    "idx = 1 # Sample index related to json order\n",
    "img_idx = all_img_idx[idx]\n",
    "img_name = all_img_name[idx]\n",
    "\n",
    "dat = th.utils.data.Subset(dataset, indices=img_idx)\n",
    "subset_loader = th.utils.data.DataLoader(dat, batch_size=2,\n",
    "                                    shuffle=False, num_workers=24)\n",
    "                            \n",
    "dat, model_kwargs = list(iter(subset_loader))[0]\n",
    "show(torchvision.utils.make_grid((dat[[0]] + 1) * 127.5/255.0))\n",
    "out = inversion(dat=dat, idx=0, use_global_norm=True, norm_img=True, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.shape)\n",
    "show(torchvision.utils.make_grid(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e726457752a9f31dd08e885b4d7ad782b9d2db89819f0ec82c996add1b497d76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
